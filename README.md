# Identification-of-alzheimer-s-disease
    
    
    这个项目是基于300名患者的脑部,MRI(核磁共振)图像数据，维度是（79,95,79）。通过机器学习的方法，这里是基于卷积神经网络，
    来识别与预测3个类别，
    这三个类别分别是：正常，轻度认知障碍，阿尔兹海默症。
    这篇代码里所涉及的关于，阿尔兹海默症的医学知识，以及参考的论文，来自下面的两个链接：
[阿尔茨海默病(AD)的影像学诊断](https://wenku.baidu.com/view/a614b73076eeaeaad0f330c9.html)

[CNN诊断阿尔兹海默症](https://github.com/791092214/Identification-of-alzheimer-s-disease/raw/master/123.pdf)

    代码大致可以分为两个部分，一个是数据的提取，一个是数据预处理、建模、训练与预测，下面将逐步进行思路的阐述。

# 第一部分——数据的提取
    这一部分可以说是整个项目的一个关键点，也耗费了最多的精力。每个样本对应了一个3D模型，在项目之初我尝试的是把一个样本，
    从各个方向进行切片，因为维度是（79,95,79），所以全部切片会得到 79+95+79 = 253张图片。把所有的这些切片数据都当做是能
    带入模型训练的数据。但最后经过训练之后，效果并不好。所以考虑对数据进行筛选，经过观察，发现有的数据很明显是没有什么意
    义的，举个例子，针对某个样本，我们取第一个维度的第一张图片，会得到这张图片，
![](https://github.com/791092214/Identification-of-alzheimer-s-disease/raw/master/1586600304(1).png)图一
    
    是不是不太看得出来这是个什么东西？接下来，让我们从第一个维度的中间部分进行取值，会得到这张图片，
    
![](https://github.com/791092214/Identification-of-alzheimer-s-disease/raw/master/1586600878(1).png)图二
    
    是不是大概就能看明白是个什么东西了。
    
    如果采用所有的切片数据，整个数据集就包含了大量的型如图一的数据，这一类型的数据显然对模型是没有帮助的。
    在对型如图一的数据进行了剔除之后，训练的效果有了小幅的提升。但是验证集的Loss依然很低。期间尝试对整个模型
    进行各种参数调优的尝试，包括正则化，缩小神经网络的规模，数据增强，等等。效果都没有明显的提升。最后还是回
    到对原始数据的选择上。所以就去查了一些专业的医学材料，然后就发现了前面第一个链接中的材料。然后就选择材料
    中提及的各个维度去进行尝试，最终找出了能让Loss最小的横切面类型。就是这个类型的横切面，
 ![](https://github.com/791092214/Identification-of-alzheimer-s-disease/raw/master/1586601750(1).png)图三
 
 # 第二部分-数据预处理、建模、训练与预测
 ## 数据预处理
    数据预处理就是将所有的像素除以255，并没有什么特别的。期间尝试过使用数据增强来生成更多的图片，但是效果都
    不好。
 ## 建模
    这个部分也起到了至关重要的作用，在一开始的时候，尝试使用vgg,restnet等经典的深度学习模型进行训练，发现效
    果并不好。然后在网上搜了些论文，就发现了前面提到的论文——CNN诊断阿尔兹海默症。然后尝试使用了里面提到的模
    型，发现效果有了很大的提升。在进一步的训练中，考虑论文中的模型可能存在“过度提取”的问题。我的意思是，源数
    据已经是质量比较高的数据集了。而论文中采取了3层，卷积-池化，来提取信息，考虑这种模型可能在信息提取过程中
    将一些本来有用的信息忽略了，所以在减少了层数，只保留一层，卷积-池化层。果然，最后效果得到了提升。
 ## 训练
    在模型的训练部分，发生了一些奇怪的事情，就是，发现当不断的重复的取运行整个程序的时候，每一个运行出来的结
    过都可能更上一次产生巨大的差别，比如，前一次运行100个epoch,Loss可能是0.3.但是，当再一次运行100个epoch的
    时候，Loss可能会直接降到0.1左右。进过分析，考虑是随机因素在产生影响。所以采取了在模型的训练中加入了checkpoint
    功能，从而总是能记录下每次训练中Loss最小那个模型。
 ## 预测
    最后，在预测的部分也踩了一些坑。一开始是采取直接使用numpy将数据resize成对应的维度导入模型，结果发现所有
    的数据预测出来都是一个结果。然后尝试着将待预测的数据集制作成test_generator,就像一开始制作train_generator
    和validation_generator那样。这样才得到了正确的结果。感觉如果使用框架，就要尽量的去使用框架内部的一些工具，
    如果自己尝试着单独弄一些东西去与框架对接，可能就会出问题。
 
